{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import configparser as cp\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sklearn \n",
    "import seaborn as sb\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#ALGORITMOS SELECIONADOS ATÉ O MOMENTO\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#-----------------------------------------\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "## mudar thema do notebook !jt -t solarizedd -T -N -kl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# config = cp.ConfigParser()\n",
    "# config.read('config.ini')\n",
    "# api_key = config['twitter_credenciais']['api_key']\n",
    "# api_key_secret = config['twitter_credenciais']['api_key_secret']\n",
    "# access_token = config['twitter_credenciais']['access_token']\n",
    "# access_token_secret = config['twitter_credenciais']['access_token_secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# auth = tw.OAuthHandler(api_key,api_key_secret)\n",
    "# auth.set_access_token(access_token,access_token_secret)\n",
    "# api = tw.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_depressao.csv')\n",
    "filter = (df['id_tweet'] == 3696)\n",
    "df.loc[filter,'psiquico'] = 0 "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.rename(columns = {'label':'target'}, inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['data_postagem'] = pd.to_datetime(df['dh_tweet']).dt.date\n",
    "df['hora_postagem'] = pd.to_datetime(df['dh_tweet']).dt.time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def limpar_tweets(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text)\n",
    "    text = re.sub(r'@[A-Za-z0-9]_+', '', text)\n",
    "    text = re.sub(r'@_[A-Za-z0-9]+', '', text)\n",
    "    text = re.sub(r'@_[A-Za-z0-9]_+', '', text)# Remove mencoes\n",
    "    text = re.sub(r'#','', text) # Remove simbolo de hashtags\n",
    "    text = re.sub(r'RT[\\s]+','',text) # Remove Retweets\n",
    "    text = re.sub(r'https?:/\\/\\S+','',text) # Remove URLS\n",
    "\n",
    "    regrex_pattern = re.compile(pattern = \"[\"   #Remove todos os emojis\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'', text)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['tweets'] = df['ds_tweet'].apply(limpar_tweets)\n",
    "df.head()\n",
    "len(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop(df[df['tweets'] == ''].index)\n",
    "len(df.index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stop = stopwords.words(\"portuguese\")\n",
    "\n",
    "print(stop)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## removendo os stopwords\n",
    "df[\"tweets\"] = df[\"tweets\"].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(df[\"tweets\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    lemma_words = [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "    return \" \".join(lemma_words)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"tweets\"] = df[\"tweets\"].apply(lemmatize_text)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BagOfWords = CountVectorizer()\n",
    "BagOfWords.fit_transform(df['tweets'])\n",
    "BagOfWords.get_feature_names_out()\n",
    "BagOfWords_result = BagOfWords.transform(df['tweets'])\n",
    "\n",
    "\n",
    "\n",
    "# tfidf_vec = TfidfVectorizer(use_idf=True)\n",
    "\n",
    "#                     tfidf_vec.fit(input_df[‘text’])\n",
    "\n",
    "#                     tfidf_result = tfidf_vec.transform(input_df[‘text’])\n",
    "\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(BagOfWords_result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(use_idf=True)\n",
    "tfidf_vec.fit(df['tweets'])\n",
    "tfidf_result = tfidf_vec.transform(df['tweets'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(tfidf_result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#SEPARA OS CONJUNTOS DE TREINAMENTO E TESTE\n",
    "X = tfidf_result   #Caso necessite usar o metodo TFIDF apenas trocar essa variavel por tfidf_result\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### TESTE COM ARVORE DE DECISÃO\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#Acuracidade\n",
    "\n",
    "\n",
    "print(\"MATRIZ DE CONFUSAO\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "print(\"ACURACIDADE\")\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# F1-SCORE\n",
    "\n",
    "# f1 = f1_score(y_test, y_pred,pos_label='positive', average='micro')\n",
    "# print(f1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"F1 Score : \",f1_score(y_test, y_pred, average=None))\n",
    "print(\"Precision Score : \",precision_score(y_test, y_pred, \n",
    "                                           average=None))\n",
    "print(\"Recall Score : \",recall_score(y_test, y_pred, \n",
    "                                           average=None))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sb.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap='Blues', fmt='g')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### TESTE COM ENSEMBLE RANDOM FOREST\n",
    "\n",
    "rnd_mdl = RandomForestClassifier()\n",
    "rnd_mdl.fit(X_train, y_train)\n",
    "#Using the fitted model to predict from the test data\n",
    "\n",
    "#test_df is the test data and tfidf_result_test is the preprocessed test text data\n",
    "\n",
    "y_pred = rnd_mdl.predict(X_test)\n",
    "\n",
    "#Acuracidade \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"MATRIZ DE CONFUSAO\")\n",
    "print(cm)\n",
    "    \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"ACURACIDADE\")\n",
    "print(accuracy)\n",
    "\n",
    "#F1-SCORE\n",
    "\n",
    "#f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"F1 Score : \",f1_score(y_test, y_pred, average=None))\n",
    "print(\"Precision Score : \",precision_score(y_test, y_pred, \n",
    "                                           average=None))\n",
    "print(\"Recall Score : \",recall_score(y_test, y_pred, \n",
    "                                           average=None))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sb.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap='Blues', fmt='g')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TESTE COM KNN\n",
    "knn = KNeighborsClassifier(3)\n",
    "\n",
    "X = BagOfWords_result\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "#Acuracidade\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"MATRIZ DE CONFUSAO\")\n",
    "print(cm)\n",
    "    \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"ACURACIDADE\")\n",
    "print(accuracy)\n",
    "\n",
    "#F1-SCORE\n",
    "\n",
    "#f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"F1 Score : \",f1_score(y_test, y_pred, average=None))\n",
    "print(\"Precision Score : \",precision_score(y_test, y_pred, \n",
    "                                           average=None))\n",
    "print(\"Recall Score : \",recall_score(y_test, y_pred, \n",
    "                                           average=None))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sb.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap='Blues', fmt='g')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## TESTE COM REGRESSÃO LOGISTICA\n",
    "lr = LogisticRegression()\n",
    "\n",
    "\n",
    "lr.fit(X_train, y_train)                  # Emprega o conjunto de treinamento \n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"MATRIZ DE CONFUSAO\")\n",
    "print(cm)\n",
    "    \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"ACURACIDADE\")\n",
    "print(accuracy)\n",
    "\n",
    "#F1-SCORE\n",
    "\n",
    "#f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"F1 Score : \",f1_score(y_test, y_pred, average=None))\n",
    "print(\"Precision Score : \",precision_score(y_test, y_pred, \n",
    "                                           average=None))\n",
    "print(\"Recall Score : \",recall_score(y_test, y_pred, \n",
    "                                           average=None))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sb.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap='Blues', fmt='g')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}